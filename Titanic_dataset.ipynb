{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.api.types import is_numeric_dtype\nfrom pandas.api.types import is_string_dtype\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn import preprocessing, neighbors\nfrom sklearn import tree\nfrom sklearn import linear_model\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.compat.v1 import placeholder\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nimport re\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"gender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\npid = test['PassengerId']\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n#print(test['Sex'])\n\nfor data in [train, test]:\n    data['rel'] = data['SibSp'] + data['Parch']\n    data.drop(['PassengerId', 'Ticket'], 1, inplace = True)\n    data['Fare'].fillna(data['Fare'].mean(), inplace = True)\n    data.Fare = np.ceil(train.Fare/30)\n    data['Age'].fillna(data['Age'].mean(), inplace = True)\n    data['Age'] = np.ceil((data['Age']/5))\n    data['Embarked'].fillna('S')\n    data['Cabin'] = data['Cabin'].fillna('U0')\n    data['Deck'] = [x[0] for x in data['Cabin']]\n    data.drop(['Cabin','SibSp', 'Parch', 'Name'], 1, inplace = True)\n\n   \n    \n    for col in ['Embarked', 'Deck', 'Sex']:\n        a = pd.get_dummies(data[col])\n        s = 0;\n        for i in a:\n            a[i] = a[i]*s\n            s = s+1\n            data[col] = a.sum(axis = 1)\n        # extract titles\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train)\nprint(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in train:\n    a = train[k]\n    #f, c =np.unique(a, return_counts=True)  \n    print(train[k].value_counts())\n    #print(k)\n    #print(f)\n    #print(c)\n    \n#for col in ['Embarked', 'Deck', 'Sex']:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = test.Pclass\nf, c =np.unique(a, return_counts=True)  \nprint(f)\nprint(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"      \n        #data[col] = pd.to_numeric(pd.Series(data[col]), errors='coerce')\n        #if is_numeric_dtype(data[col]):\n        #    data[col] = data[col].fillna(data[col].mean(), inplace = True)\n        #    #print(str(train[col].mean()) + \" \" + col)\n        #if is_string_dtype(data[col]):\n        #    dct = dict(zip(data[col].unique(), list(range(0, len(data[col].unique())))))\n        #    data = data.replace({col: dct})\n        #print(col)\n        #print(is_string_dtype(data[col]))\n        #print(type(data[col]))\n        \n        #print(dct)\n#for col in test:\n #  if is_numeric_dtype(test[col]):\n #       test[col].fillna(test[col].mean(), inplace = True)\n  #      #print(str(train[col].mean()) + \" \" + col)\n   # if is_string_dtype(test[col]):\n    #    dct = dict(zip(test[col].unique(), list(range(0, len(test[col].unique())))))\n     #   test = test.replace({col: dct})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(train.drop(['Survived'] ,1))\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)\ntest = scaler.transform(test)\n\ny = np.array(train['Survived'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best = 0\nwarnings.filterwarnings('ignore')\nclf = RandomForestClassifier()\nclf1 = clf\nclf.fit(X_train, y_train)\naccuracy = clf.score(X_test, y_test)\noutput = clf.predict(test)\n\nfor i in range(0, 10):\n    clf = RandomForestClassifier()\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    if best < accuracy:\n        best = accuracy \n        output = clf.predict(test)\n\n\n    clf = svm.SVC()\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    if best < accuracy:\n        best = accuracy \n        output = clf.predict(test)\n\n\n    clf = KNeighborsClassifier()\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    if best < accuracy:\n        best = accuracy \n        output = clf.predict(test)\n\n\n    clf = linear_model.LogisticRegression()\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    if best < accuracy:\n        best = accuracy \n        output = clf.predict(test)\n\n\n    clf = GaussianNB()\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    if best < accuracy:\n        best = accuracy \n        output = clf.predict(test)\n\n\n    clf = svm.LinearSVC()\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    if best < accuracy:\n        best = accuracy \n        output = clf.predict(test)\n\n\n    clf = linear_model.SGDClassifier()\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    if best < accuracy:\n        best = accuracy \n        output = clf.predict(test)\n\n\nwarnings.filterwarnings('ignore')\nprint(best)\nprint(output)\n#print(clf1)\nsubmission = pd.DataFrame({\n        \"PassengerId\": pid,\n        \"Survived\": output\n    })\n\nsubmission.to_csv('../input/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = svm.SVC()\nclf.fit(X_train, y_train)\naccuracy = clf.score(X_test, y_test)\noutput = clf.predict(test)\nprint(accuracy)\nprint(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nbest = 0\nwarnings.filterwarnings('ignore')\nlr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n\nfor learning_rate in lr_list:\n    clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n    clf.fit(X_train, y_train)\n#clf.fit(X_train, y_train)\naccuracy = clf.score(X_test, y_test)\noutput = clf.predict(test)\n\n\nprint(accuracy)\nprint(output)\nsubmission = pd.DataFrame({\n        \"PassengerId\": pid,\n        \"Survived\": output\n})\nsubmission.to_csv('../input/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kaggle competitions submit -c titanic -f submission.csv -m \"Message\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.remove('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.DataFrame({'HPI':[80,85,88,85],\n                    'Int_rate':[2, 3, 2, 2],\n                    'US_GDP_Thousands':['dfa', 'fs', 'fsd', 'fs']},\n                   index = [2001, 2002, 2003, 2004])\nprint(df1)\na = pd.get_dummies(df1['US_GDP_Thousands'], drop_first = True)\nprint(a)\ns = 0;\nfor i in a:\n    \n    a[i] = a[i]*(2**s)\n    s = s+1\n    print(a[i])\nprint(a)\n\n\ndf1['US_GDP_Thousands'] = a.sum(axis = 1)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/titanic/train.csv\")\ndf.columns\na = np.ceil(df.Fare/20)\ndf.Fare =a\nf, c =np.unique(a, return_counts=True)\nprint(c)\nprint(f*20)\n#print(len(f))\nfor i in f:\n    print(i)\n    w, g =np.unique(df.loc[df['Fare'] == i].Survived, return_counts=True)\n    print(w)\n    print(g)\n    #print(df.loc[df['Fare'] == i].Survived.unique())\n#df.Fare.unique()    \n#df.loc[df['Fare'] == 2.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/titanic/train.csv\")\ndf['Cabin'] = df['Cabin'].fillna('U0')\ndf['Cabin'][67]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1} 
